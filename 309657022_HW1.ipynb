{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW1: Linear Regression using Gradient Descent\n",
    "In hw1, you need to implement linear regression by using only numpy, then train your implemented model by the provided dataset and test the performance with testing data\n",
    "\n",
    "Please note that only **NUMPY** can be used to implement your model, you will get no points by simply calling sklearn.linear_model.LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train_data.csv\")\n",
    "x_train, y_train = train_df['x_train'], train_df['y_train']\n",
    "test_data = pd.read_csv(\"test_data.csv\")\n",
    "x_test, y_test = test_data['x_test'], test_data['y_test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model \n",
    "### Pseudo code:\n",
    "1. Random initialize the weights, intercepts of the linear model\n",
    "\n",
    "**for i in range(iteration)**\n",
    "\n",
    "    2. Feed foward the training data into the model, get the output prediction\n",
    "    3. Calculating training loss by Mean Square Error of predcition and ground truth data\n",
    "    4. Calculating the gradients\n",
    "    5. Updating the weights and intercepts by the gradients * learning rate \n",
    "    \n",
    "**End of training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_model_gradient_descent(x_train, y_train, learning_rate=1e-4, iteration=100, loss_function=\"MSE\"):\n",
    "    #Random initialize the weights, intercepts of the linear model\n",
    "    weight = np.random.normal(0, np.var(x_train), x_train.ndim+1)\n",
    "    \n",
    "    loss = []\n",
    "    \n",
    "    for i in range(iteration):\n",
    "        #Feed foward the training data into the model, get the output prediction\n",
    "        y_pred = sum([weight[0], weight[1]*x_train]) \n",
    "        \n",
    "        #Calculating training loss by Mean Square Error of predcition and ground truth data\n",
    "        error = y_train - y_pred\n",
    "        n = x_train.shape[0]\n",
    "        loss.append(sum(error**2)/n)\n",
    "        \n",
    "        #Calculating the gradients\n",
    "        gradient = [(-2)*sum(error)/n, (-2)*sum(error*x_train)/n]\n",
    "        \n",
    "        #Updating the weights and intercepts by the gradients * learning rate \n",
    "        weight[0] = weight[0] - gradient[0]*learning_rate\n",
    "        weight[1] = weight[1] - gradient[1]*learning_rate\n",
    "    \n",
    "    #return the values of the least weights and loss of each iteration\n",
    "    return loss, weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. (15%) Plot the learning curve of the training, you should find that loss decreases after a few iterations (x-axis=iteration, y-axis=loss, Matplotlib or other plot tools is\n",
    "available to use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1959454eb50>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = linear_model_gradient_descent(x_train, y_train, learning_rate=1e-1, iteration=100, loss_function=\"mse\")\n",
    "plt.plot(model[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the performance on the testing data\n",
    "Inference the test data (x_test) by your model and calculate the MSE of (y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. (15%) What’s the Mean Square Error of your prediction and ground truth\n",
    "(prediction=model(x_test), ground truth=y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Square Error=0.06870297322189324\n"
     ]
    }
   ],
   "source": [
    "train_weight = model[1]\n",
    "y_pred = sum([train_weight[0], train_weight[1]*x_test]) \n",
    "mse = sum((y_test - y_pred)**2)/y_test.shape[0]\n",
    "print(\"Mean Square Error=\"+str(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. (15%) What’re the weights and intercepts of your linear model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight=0.8179703769483088 ;intercept=0.7845650819708999\n"
     ]
    }
   ],
   "source": [
    "print(\"weight=\"+str(train_weight[1])+\" ;intercept=\"+str(train_weight[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. (10%) What’s the difference between Gradient Descent, Mini-Batch Gradient\n",
    "Descent, and Stochastic Gradient Descent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Descent calculates the partial differential of loss function within all data points given, whereas Mini-Batch Gradient Descent is given some data points, which we call it \"batch\", and Stochastic Gradient Descent just given one data point every time. Thererfore, calculating time of each iteration is Gradient Descent > Mini-Batch Gradient Descent > Stochastic Gradient Descent, but the speed of the convergence is Gradient Descent > Mini-Batch Gradient Descent > Stochastic Gradient Descent."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
